{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_webinar_6_cude.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/map72ru/data_mining/blob/main/hw_webinar_6_cude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMBdGcvjC4Ji"
      },
      "source": [
        "# Вебинар 6. Двухуровневые модели рекомендаций\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jgaacz0C4Jl"
      },
      "source": [
        "Код для src, utils, metrics вы можете скачать из [этого](https://github.com/geangohn/recsys-tutorial) github репозитория"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRpYkHeiailc",
        "outputId": "e41fef4b-3b55-4658-b40b-4fa93325ccb9"
      },
      "source": [
        "!pip install implicit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting implicit\n",
            "  Downloading implicit-0.4.8.tar.gz (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 583 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 593 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 604 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 614 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 624 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 634 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 645 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 655 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 665 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 675 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 686 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 696 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 706 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 716 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 727 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 737 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 747 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 757 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 768 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 778 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 788 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 798 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 808 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 819 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 829 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 839 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 849 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 860 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 870 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 880 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 890 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 901 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 911 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 921 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 931 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 942 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 952 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 962 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 972 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 983 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 993 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from implicit) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from implicit) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from implicit) (4.62.3)\n",
            "Building wheels for collected packages: implicit\n",
            "  Building wheel for implicit (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for implicit: filename=implicit-0.4.8-cp37-cp37m-linux_x86_64.whl size=4606606 sha256=346d052f68c82b5b43ce1549272cdbd377779f7e67192eb2c0fea6173a64f5af\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/e6/34/25e73cccbaf1a961154bb562a5f86123b68fdbf40e306073d6\n",
            "Successfully built implicit\n",
            "Installing collected packages: implicit\n",
            "Successfully installed implicit-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woXQdnkz9I1n"
      },
      "source": [
        "#\n",
        "# Кода модулей взяты из ДЗ за исключением \n",
        "# recalculate_user=False\n",
        "## Код stc/metrics.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def precision(recommended_list, bought_list):\n",
        "    \n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    \n",
        "    flags = np.isin(bought_list, recommended_list)\n",
        "    \n",
        "    precision = flags.sum() / len(recommended_list)\n",
        "    \n",
        "    return precision\n",
        "\n",
        "\n",
        "def precision_at_k(recommended_list, bought_list, k=5):\n",
        "    \n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    \n",
        "    bought_list = bought_list  # Тут нет [:k] !!\n",
        "    recommended_list = recommended_list[:k]\n",
        "    \n",
        "    flags = np.isin(bought_list, recommended_list)\n",
        "    \n",
        "    precision = flags.sum() / len(recommended_list)\n",
        "    \n",
        "    \n",
        "    return precision\n",
        "\n",
        "\n",
        "def money_precision_at_k(recommended_list, bought_list, prices_recommended, k=5):\n",
        "        \n",
        "    # your_code\n",
        "    # Лучше считать через матричное произведение, а не цикл\n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    prices_recommended = np.array(prices_recommended)\n",
        "    \n",
        "    recommended_list = recommended_list[:k]\n",
        "    prices_recommended = prices_recommended[:k]\n",
        "    \n",
        "    # Почему здесь изменен порядок в функции isin?\n",
        "    flags = np.isin(recommended_list, bought_list)\n",
        "    \n",
        "    relevant_revenue = (flags * prices_recommended).sum()\n",
        "    recommended_revenue = prices_recommended.sum()\n",
        "    \n",
        "    precision = relevant_revenue / recommended_revenue\n",
        "    \n",
        "    return precision\n",
        "\n",
        "def recall(recommended_list, bought_list):\n",
        "    \n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    \n",
        "    flags = np.isin(bought_list, recommended_list)\n",
        "    \n",
        "    recall = flags.sum() / len(bought_list)\n",
        "    \n",
        "    return recall\n",
        "\n",
        "\n",
        "def recall_at_k(recommended_list, bought_list, k=5):\n",
        "    \n",
        "    # your code\n",
        "    recall_at_k = recall(recommended_list[:k], bought_list)\n",
        "    \n",
        "    return recall_at_k\n",
        "\n",
        "\n",
        "def money_recall_at_k(recommended_list, bought_list, prices_recommended, prices_bought, k=5):\n",
        "    \n",
        "    # your_code\n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    prices_recommended = np.array(prices_recommended)\n",
        "    prices_bought = np.array(prices_bought)\n",
        "\n",
        "    \n",
        "    assert recommended_list.shape == prices_recommended.shape\n",
        "    assert bought_list.shape == prices_bought.shape\n",
        "    \n",
        "    \n",
        "    recommended_list = recommended_list[:k]\n",
        "    prices_recommended = prices_recommended[:k]\n",
        "    \n",
        "    \n",
        "    flags = np.isin(bought_list, recommended_list)\n",
        "    \n",
        "    money_recall = (flags * prices_bought).sum() / (prices_bought).sum()\n",
        "    \n",
        "    return money_recall\n",
        "\n",
        "  ## Код src/utils.py\n",
        "\n",
        "  import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def prefilter_items(data, take_n_popular=5000, item_features=None):\n",
        "    # Уберем самые популярные товары (их и так купят)\n",
        "    popularity = data.groupby('item_id')['user_id'].nunique().reset_index() / data['user_id'].nunique()\n",
        "    popularity.rename(columns={'user_id': 'share_unique_users'}, inplace=True)\n",
        "\n",
        "    top_popular = popularity[popularity['share_unique_users'] > 0.2].item_id.tolist()\n",
        "    data = data[~data['item_id'].isin(top_popular)]\n",
        "\n",
        "    # Уберем самые НЕ популярные товары (их и так НЕ купят)\n",
        "    top_notpopular = popularity[popularity['share_unique_users'] < 0.02].item_id.tolist()\n",
        "    data = data[~data['item_id'].isin(top_notpopular)]\n",
        "\n",
        "    # Уберем товары, которые не продавались за последние 12 месяцев\n",
        "\n",
        "    # Уберем не интересные для рекоммендаций категории (department)\n",
        "    if item_features is not None:\n",
        "        department_size = pd.DataFrame(item_features.\\\n",
        "                                        groupby('department')['item_id'].nunique().\\\n",
        "                                        sort_values(ascending=False)).reset_index()\n",
        "\n",
        "        department_size.columns = ['department', 'n_items']\n",
        "        rare_departments = department_size[department_size['n_items'] < 150].department.tolist()\n",
        "        items_in_rare_departments = item_features[item_features['department'].isin(rare_departments)].item_id.unique().tolist()\n",
        "\n",
        "        data = data[~data['item_id'].isin(items_in_rare_departments)]\n",
        "\n",
        "\n",
        "    # Уберем слишком дешевые товары (на них не заработаем). 1 покупка из рассылок стоит 60 руб.\n",
        "    data['price'] = data['sales_value'] / (np.maximum(data['quantity'], 1))\n",
        "    data = data[data['price'] > 2]\n",
        "\n",
        "    # Уберем слишком дорогие товарыs\n",
        "    data = data[data['price'] < 50]\n",
        "\n",
        "    # Возбмем топ по популярности\n",
        "    popularity = data.groupby('item_id')['quantity'].sum().reset_index()\n",
        "    popularity.rename(columns={'quantity': 'n_sold'}, inplace=True)\n",
        "\n",
        "    popularity.index = popularity.index.astype('int')\n",
        "    top = popularity.sort_values('n_sold', ascending=False).head(int(take_n_popular)).item_id.tolist()\n",
        "    \n",
        "    # Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
        "    data.loc[~data['item_id'].isin(top), 'item_id'] = 999999\n",
        "    \n",
        "    # ...\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def postfilter_items(user_id, recommednations):\n",
        "    pass\n",
        "\n",
        "\n",
        "## код src/recommenders.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Для работы с матрицами\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Матричная факторизация\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from implicit.nearest_neighbours import ItemItemRecommender  # нужен для одного трюка\n",
        "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
        "\n",
        "\n",
        "class MainRecommender:\n",
        "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    user_item_matrix: pd.DataFrame\n",
        "        Матрица взаимодействий user-item\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, weighting=True):\n",
        "\n",
        "        # Топ покупок каждого юзера\n",
        "        self.top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
        "        self.top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
        "        self.top_purchases = self.top_purchases[self.top_purchases['item_id'] != 999999]\n",
        "\n",
        "        # Топ покупок по всему датасету\n",
        "        self.overall_top_purchases = data.groupby('item_id')['quantity'].count().reset_index()\n",
        "        self.overall_top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
        "        self.overall_top_purchases = self.overall_top_purchases[self.overall_top_purchases['item_id'] != 999999]\n",
        "        self.overall_top_purchases = self.overall_top_purchases.item_id.tolist()\n",
        "\n",
        "        self.user_item_matrix = self._prepare_matrix(data)  # pd.DataFrame\n",
        "        self.id_to_itemid, self.id_to_userid, \\\n",
        "            self.itemid_to_id, self.userid_to_id = self._prepare_dicts(self.user_item_matrix)\n",
        "\n",
        "        if weighting:\n",
        "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T\n",
        "\n",
        "        self.model = self.fit(self.user_item_matrix)\n",
        "        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n",
        "\n",
        "    @staticmethod\n",
        "    def _prepare_matrix(data):\n",
        "        \"\"\"Готовит user-item матрицу\"\"\"\n",
        "        user_item_matrix = pd.pivot_table(data,\n",
        "                                          index='user_id', columns='item_id',\n",
        "                                          values='quantity',  # Можно пробовать другие варианты\n",
        "                                          aggfunc='count',\n",
        "                                          fill_value=0\n",
        "                                          )\n",
        "\n",
        "        user_item_matrix = user_item_matrix.astype(float)  # необходимый тип матрицы для implicit\n",
        "\n",
        "        return user_item_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def _prepare_dicts(user_item_matrix):\n",
        "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
        "\n",
        "        userids = user_item_matrix.index.values\n",
        "        itemids = user_item_matrix.columns.values\n",
        "\n",
        "        matrix_userids = np.arange(len(userids))\n",
        "        matrix_itemids = np.arange(len(itemids))\n",
        "\n",
        "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
        "        id_to_userid = dict(zip(matrix_userids, userids))\n",
        "\n",
        "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
        "        userid_to_id = dict(zip(userids, matrix_userids))\n",
        "\n",
        "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
        "\n",
        "    @staticmethod\n",
        "    def fit_own_recommender(user_item_matrix):\n",
        "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
        "\n",
        "        own_recommender = ItemItemRecommender(K=1, num_threads=4)\n",
        "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
        "\n",
        "        return own_recommender\n",
        "\n",
        "    @staticmethod\n",
        "    def fit(user_item_matrix, n_factors=20, regularization=0.001, iterations=15, num_threads=4):\n",
        "        \"\"\"Обучает ALS\"\"\"\n",
        "\n",
        "        model = AlternatingLeastSquares(factors=n_factors,\n",
        "                                        regularization=regularization,\n",
        "                                        iterations=iterations,\n",
        "                                        num_threads=num_threads)\n",
        "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _update_dict(self, user_id):\n",
        "        \"\"\"Если появился новыю user / item, то нужно обновить словари\"\"\"\n",
        "\n",
        "        if user_id not in self.userid_to_id.keys():\n",
        "\n",
        "            max_id = max(list(self.userid_to_id.values()))\n",
        "            max_id += 1\n",
        "\n",
        "            self.userid_to_id.update({user_id: max_id})\n",
        "            self.id_to_userid.update({max_id: user_id})\n",
        "\n",
        "    def _get_similar_item(self, item_id):\n",
        "        \"\"\"Находит товар, похожий на item_id\"\"\"\n",
        "        recs = self.model.similar_items(self.itemid_to_id[item_id], N=2)  # Товар похож на себя -> рекомендуем 2 товара\n",
        "        top_rec = recs[1][0]  # И берем второй (не товар из аргумента метода)\n",
        "        return self.id_to_itemid[top_rec]\n",
        "\n",
        "    def _extend_with_top_popular(self, recommendations, N=5):\n",
        "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
        "\n",
        "        if len(recommendations) < N:\n",
        "            recommendations.extend(self.overall_top_purchases[:N])\n",
        "            recommendations = recommendations[:N]\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def _get_recommendations(self, user, model, N=5):\n",
        "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
        "\n",
        "        self._update_dict(user_id=user)\n",
        "        csr = csr_matrix(self.user_item_matrix).tocsr()\n",
        "        res = [self.id_to_itemid[rec[0]] for rec in model.recommend(userid=self.userid_to_id[user],\n",
        "                                        user_items=csr,\n",
        "                                        N=N,\n",
        "                                        filter_already_liked_items=False,\n",
        "                                        filter_items=[self.itemid_to_id[999999]],\n",
        "                                        recalculate_user=False)]\n",
        "\n",
        "        res = self._extend_with_top_popular(res, N=N)\n",
        "\n",
        "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
        "        return res\n",
        "\n",
        "    def get_als_recommendations(self, user, N=5):\n",
        "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
        "\n",
        "        self._update_dict(user_id=user)\n",
        "        return self._get_recommendations(user, model=self.model, N=N)\n",
        "\n",
        "    def get_own_recommendations(self, user, N=5):\n",
        "        \"\"\"Рекомендуем товары среди тех, которые юзер уже купил\"\"\"\n",
        "\n",
        "        self._update_dict(user_id=user)\n",
        "        return self._get_recommendations(user, model=self.own_recommender, N=N)\n",
        "\n",
        "    def get_similar_items_recommendation(self, user, N=5):\n",
        "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
        "\n",
        "        top_users_purchases = self.top_purchases[self.top_purchases['user_id'] == user].head(N)\n",
        "\n",
        "        res = top_users_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n",
        "        res = self._extend_with_top_popular(res, N=N)\n",
        "\n",
        "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
        "        return res\n",
        "\n",
        "    def get_similar_users_recommendation(self, user, N=5):\n",
        "        \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
        "\n",
        "        res = []\n",
        "\n",
        "        # Находим топ-N похожих пользователей\n",
        "        similar_users = self.model.similar_users(self.userid_to_id[user], N=N+1)\n",
        "        similar_users = [rec[0] for rec in similar_users]\n",
        "        similar_users = similar_users[1:]   # удалим юзера из запроса\n",
        "\n",
        "        for user in similar_users:\n",
        "            res.extend(self.get_own_recommendations(user, N=1))\n",
        "\n",
        "        res = self._extend_with_top_popular(res, N=N)\n",
        "\n",
        "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
        "        return res\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5pEPDEsaDvC",
        "outputId": "b5278b8a-3c4f-4166-9688-095d61f5fcf3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/hw2')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/hw2/MyDrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/hw2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Aur99NsC4Jm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Для работы с матрицами\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Матричная факторизация\n",
        "from implicit import als\n",
        "\n",
        "# Модель второго уровня\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import os, sys\n",
        "module_path = os.path.abspath(os.path.join(os.pardir))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "# Написанные нами функции\n",
        "from src.metrics import precision_at_k, recall_at_k\n",
        "from src.utils import prefilter_items\n",
        "from src.recommenders import MainRecommender"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vso_erSdC4Jo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "d37020a2-9dfd-4697-8c8f-9c152efe1eb7"
      },
      "source": [
        "data = pd.read_csv('/content/hw2/MyDrive/data/retail_train.csv')\n",
        "item_features = pd.read_csv('/content/hw2/MyDrive/data/product.csv')\n",
        "user_features = pd.read_csv('/content/hw2/MyDrive/data/hh_demographic.csv')\n",
        "\n",
        "# column processing\n",
        "item_features.columns = [col.lower() for col in item_features.columns]\n",
        "user_features.columns = [col.lower() for col in user_features.columns]\n",
        "\n",
        "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
        "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
        "\n",
        "\n",
        "# Важна схема обучения и валидации!\n",
        "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
        "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
        "val_lvl_1_size_weeks = 6\n",
        "val_lvl_2_size_weeks = 3\n",
        "\n",
        "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
        "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
        "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
        "\n",
        "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
        "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
        "\n",
        "data_train_lvl_1.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>basket_id</th>\n",
              "      <th>day</th>\n",
              "      <th>item_id</th>\n",
              "      <th>quantity</th>\n",
              "      <th>sales_value</th>\n",
              "      <th>store_id</th>\n",
              "      <th>retail_disc</th>\n",
              "      <th>trans_time</th>\n",
              "      <th>week_no</th>\n",
              "      <th>coupon_disc</th>\n",
              "      <th>coupon_match_disc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2375</td>\n",
              "      <td>26984851472</td>\n",
              "      <td>1</td>\n",
              "      <td>1004906</td>\n",
              "      <td>1</td>\n",
              "      <td>1.39</td>\n",
              "      <td>364</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>1631</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2375</td>\n",
              "      <td>26984851472</td>\n",
              "      <td>1</td>\n",
              "      <td>1033142</td>\n",
              "      <td>1</td>\n",
              "      <td>0.82</td>\n",
              "      <td>364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1631</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id    basket_id  day  ...  week_no  coupon_disc  coupon_match_disc\n",
              "0     2375  26984851472    1  ...        1          0.0                0.0\n",
              "1     2375  26984851472    1  ...        1          0.0                0.0\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcnV3l4XC4Jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48c99f6-d098-49ff-901a-0cacd58ace8c"
      },
      "source": [
        "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
        "\n",
        "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n",
        "\n",
        "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
        "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decreased # items from 83685 to 5001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "zgYXRQ0lC4Jq",
        "outputId": "da3158fd-678d-4fa6-94dd-dca14734b655"
      },
      "source": [
        "recommender = MainRecommender(data_train_lvl_1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-459d826d366b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMainRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_lvl_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/hw2/MyDrive/src/recommenders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, weighting)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_item_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_item_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_item_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mown_recommender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_own_recommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_item_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hw2/MyDrive/src/recommenders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(user_item_matrix, n_factors, regularization, iterations, num_threads)\u001b[0m\n\u001b[1;32m     91\u001b[0m                                         \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                                         \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                                         num_threads=num_threads)\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_item_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/implicit/als.py\u001b[0m in \u001b[0;36mAlternatingLeastSquares\u001b[0;34m(factors, regularization, dtype, use_native, use_cg, use_gpu, iterations, calculate_training_loss, num_threads, random_state)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mcalculate_training_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_training_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         )\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/implicit/gpu/als.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, factors, regularization, iterations, calculate_training_loss, random_state)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No CUDA extension has been built, can't train on GPU.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAlternatingLeastSquares\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# parameters on how to factorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/implicit/gpu/matrix_factorization_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKnnQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     def recommend(\n",
            "\u001b[0;32mimplicit/gpu/_cuda.pyx\u001b[0m in \u001b[0;36mimplicit.gpu._cuda.KnnQuery.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cuda Error: no CUDA-capable device is detected (implicit/gpu/device_buffer.cu:12)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucaH6ENTs7VS",
        "outputId": "cc8f4fb5-bf71-4a7d-af12-d09d94307fd8"
      },
      "source": [
        "recommender.model.user_factors[2369]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([[0.5857185  0.44868448 0.44649413 0.41923732 0.5651236  0.368706\n",
              "  0.85684896 0.5908932  0.6464624  0.15077178 0.9556885  0.24161567\n",
              "  0.18162312 0.88918    0.22130758 0.8773702  0.4033972  0.8822239\n",
              "  0.12945062 0.7031214 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB9JX5swC4Jr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "91120bdf-60fe-41f3-dc10-07112444f6e6"
      },
      "source": [
        "recommender.get_als_recommendations(2375, N=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-de84b4cb61a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_als_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2375\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/hw2/MyDrive/src/recommenders.py\u001b[0m in \u001b[0;36mget_als_recommendations\u001b[0;34m(self, user, N)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_own_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hw2/MyDrive/src/recommenders.py\u001b[0m in \u001b[0;36m_get_recommendations\u001b[0;34m(self, user, model, N)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                         \u001b[0mfilter_already_liked_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                         \u001b[0mfilter_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemid_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m999999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                                         recalculate_user=False)]\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_with_top_popular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/implicit/gpu/matrix_factorization_base.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, userid, user_items, N, filter_already_liked_items, filter_items, recalculate_user)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# calculate the top N items, removing the users own liked items from the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# TODO: own like filtering (direct in topk class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         return list(\n\u001b[1;32m     53\u001b[0m             \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mliked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mimplicit/gpu/_cuda.pyx\u001b[0m in \u001b[0;36mimplicit.gpu._cuda.Matrix.__getitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: don't know how to handle __getitem__ on 2369"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNVa6jWLC4Jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2879cadd-04eb-4120-c3c1-86c002d5706f"
      },
      "source": [
        "recommender.get_own_recommendations(2375, N=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[948640, 918046, 847962, 907099, 873980]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NoB_lSJC4Js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a39041b-d000-41cc-b664-2ad711ab3360"
      },
      "source": [
        "recommender.get_similar_items_recommendation(2375, N=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[117847, 117847, 117847, 117847, 117847]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdQO5CWKC4Js",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0b27e58d-3b3c-4564-8f84-3e4ae36a983a"
      },
      "source": [
        "recommender.get_similar_users_recommendation(2375, N=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-09a0b3998b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_similar_users_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2375\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/hw2/MyDrive/src/recommenders.py\u001b[0m in \u001b[0;36mget_similar_users_recommendation\u001b[0;34m(self, user, N)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_users\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_own_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_with_top_popular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hw2/MyDrive/src/recommenders.py\u001b[0m in \u001b[0;36mget_own_recommendations\u001b[0;34m(self, user, N)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mown_recommender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_similar_items_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hw2/MyDrive/src/recommenders.py\u001b[0m in \u001b[0;36m_get_recommendations\u001b[0;34m(self, user, model, N)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                         \u001b[0mfilter_already_liked_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                         \u001b[0mfilter_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemid_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m999999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                                         recalculate_user=False)]\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_with_top_popular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/implicit/nearest_neighbours.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, userid, user_items, N, filter_already_liked_items, filter_items, recalculate_user)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;34m\"\"\"returns the best N recommendations for a user given its id\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muserid\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0muser_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"userid is out of bounds of the user_items matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# recalculate_user is ignored because this is not a model based algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: userid is out of bounds of the user_items matrix"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqs9Sw_YC4Jt"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
        "- Пока пробуем отобрать 50 кандидатов (k=50)\n",
        "- Качество измеряем на data_val_lvl_1: следующие 6 недель после трейна\n",
        "\n",
        "Дают ли own recommendtions + top-popular лучший recall?  \n",
        "\n",
        "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}  \n",
        "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY1rQ8zq57WF"
      },
      "source": [
        "userid = 2372\n",
        "k = 50\n",
        "\n",
        "user_items_id = data_val_lvl_1.query('user_id == @userid').item_id.unique()\n",
        "\n",
        "recomended_items_id = recommender.get_als_recommendations(userid, N=k)\n",
        "\n",
        "als_recall = recall_at_k(recomended_items_id, user_items_id, k)\n",
        "print(f\"als={als_recall}\")\n",
        "\n",
        "recomended_items_id = recommender.get_own_recommendations(userid, N=k)\n",
        "own_recall = recall_at_k(recomended_items_id, user_items_id, k)\n",
        "print(f\"own={own_recall}\")\n",
        "\n",
        "recomended_items_id = recommender.get_similar_items_recommendation(userid, N=k)\n",
        "sitems_recall = recall_at_k(recomended_items_id, user_items_id, k)\n",
        "print(f\"similar_items={sitems_recall}\")\n",
        "\n",
        "recomended_items_id = recommender.get_similar_users_recommendation(userid, N=k)\n",
        "susers_recall = recall_at_k(recomended_items_id, user_items_id, k)\n",
        "print(f\"similar_users={susers_recall}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaAF1Iiw58l_"
      },
      "source": [
        "als=5.88235294117647\n",
        "\n",
        "own=8.823529411764707\n",
        "\n",
        "similar_items=4.411764705882353\n",
        "\n",
        "similar_users=0.0\n",
        "\n",
        "\n",
        "own+top popular дают лучший результат"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1uMIwXs8MGV"
      },
      "source": [
        "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}\n",
        "\n",
        "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frt2RzDWC4Jt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "17c06bcd-754a-423c-ce26-f8345ab8dd72"
      },
      "source": [
        "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
        "result_lvl_1.columns=['user_id', 'actual']\n",
        "result_lvl_1.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id                                             actual\n",
              "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
              "1        2  [15830248, 838136, 839656, 861272, 866211, 870..."
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5VUQzq08TWj"
      },
      "source": [
        "for m in [20, 50, 100, 200, 500]:\n",
        "    recomended_items_id = recommender.get_own_recommendations(userid, N=m)\n",
        "    own_recall = 100*recall_at_k(recomended_items_id, user_items_id, m)\n",
        "    print(f\"k = {m} own={own_recall}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnKAkmEX8Vku"
      },
      "source": [
        "k = 20 own=1.4705882352941175\n",
        "\n",
        "k = 50 own=8.823529411764707\n",
        "\n",
        "k = 100 own=13.23529411764706\n",
        "\n",
        "k = 200 own=17.647058823529413\n",
        "\n",
        "k = 500 own=27.941176470588236\n",
        "\n",
        "\n",
        "Чем больше k, тем метрика будет больше, поскольку вероятность попадания рекоментованных в купленные товары будет возростать. Если разумность значения k рассматривать чисто с математической точки зрения, то при достаточно большом K мы будем увеличивать метрику до 1. Если \"разумность\" рассмтаривать с точки зрения взаимодействия с пользователем, то самым разумным будет 20 из предложенного списка, хотя recall равен 1,47. Видно так же, что после 200 прирост точности замедляется. Я делал расчте для 1000. recall@1000 был равен 27.941176470588236\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAHJu3Z5C4Ju"
      },
      "source": [
        "### Задание 2.\n",
        "\n",
        "Обучите модель 2-ого уровня, при этом:\n",
        "    - Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар\n",
        "    - Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2\n",
        "    - Вырос ли precision@5 при использовании двухуровневой модели?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZQcrch7C4Ju"
      },
      "source": [
        "# your_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FLlIq15C4Ju"
      },
      "source": [
        "### Финальный проект\n",
        "\n",
        "Мы уже прошли всю необходимуб теорию для финального проекта. Проект осуществляется на данных из вебинара (данные считаны в начале ДЗ).\n",
        "Рекомендуем вам **начать делать проект сразу после этого домашнего задания**\n",
        "- Целевая метрика - precision@5. Порог для уcпешной сдачи проекта precision@5 > 25%\n",
        "- Будет public тестовый датасет, на котором вы сможете измерять метрику\n",
        "- Также будет private тестовый датасет для измерения финального качества\n",
        "- НЕ обязательно, но крайне желательно использовать 2-ух уровневые рекоммендательные системы в проекте\n",
        "- Вы сдаете код проекта в виде github репозитория и csv файл с рекомендациями "
      ]
    }
  ]
}